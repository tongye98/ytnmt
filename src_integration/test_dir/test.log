2023-03-06 16:03:39,468 - INFO - root - Hello! This is Tong Ye's Transformer!
2023-03-06 16:04:43,900 - INFO - data - average code tokens = 109.28999515442095
2023-03-06 16:04:43,900 - INFO - data - average ast tokens = 188.85505342888476
2023-03-06 16:04:43,900 - INFO - data - average text tokens = 15.993139680191783
2023-03-06 16:04:43,900 - INFO - data - average position tokens = 188.85505342888476
2023-03-06 16:04:43,900 - INFO - data - average ast edges = 375.7101068577695
2023-03-06 16:04:56,541 - INFO - data - code vocab length = 26684
2023-03-06 16:04:56,541 - INFO - data - text vocab length = 13207
2023-03-06 16:04:56,541 - INFO - data - position vocab length = 20587
2023-03-06 16:05:06,782 - INFO - model - Build Model...
2023-03-06 16:05:07,334 - INFO - model - The model is built.
2023-03-06 16:05:07,334 - INFO - model - Model(
	Transformer_encoder=TransformerEncoder(num_layers=6, head_count=8, layer_norm_position=pre),
	GNN_encoder=GNNEncoder(
  (layers): ModuleList(
    (0): GNNEncoderLayer(
      (gnn): SAGEConv(512, 512, aggr=mean)
      (relu): ReLU()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (1): GNNEncoderLayer(
      (gnn): SAGEConv(512, 512, aggr=mean)
      (relu): ReLU()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (2): GNNEncoderLayer(
      (gnn): SAGEConv(512, 512, aggr=mean)
      (relu): ReLU()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (3): GNNEncoderLayer(
      (gnn): SAGEConv(512, 512, aggr=mean)
      (relu): ReLU()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (4): GNNEncoderLayer(
      (gnn): SAGEConv(512, 512, aggr=mean)
      (relu): ReLU()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (5): GNNEncoderLayer(
      (gnn): SAGEConv(512, 512, aggr=mean)
      (relu): ReLU()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
),
	Transformer_decoder=TransformerDecoder(num_layers=6, head_count=8, layer_norm_position=pre),
	src_embed=Embeddings(embedding_dim=512, vocab_size=26684),
	learnable_embed=LearnablePositionalEncoding(
  (learn_lut): Embedding(400, 512)
),
	position_embed=Embeddings(embedding_dim=512, vocab_size=20587),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=13207),
	loss_function=XentLoss(criterion=NLLLoss(), smoothing=0))
2023-03-06 16:05:07,337 - INFO - model - Total parameters number: 85227008
2023-03-06 16:05:07,337 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.layer_norm.weight               [512]
2023-03-06 16:05:07,337 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.layer_norm.bias                 [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.src_src_attenion.key_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.src_src_attenion.key_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.src_src_attenion.query_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.src_src_attenion.query_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.src_src_attenion.value_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.src_src_attenion.value_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.src_src_attenion.output_layer.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.src_src_attenion.output_layer.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.0.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.layer_norm.weight               [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.layer_norm.bias                 [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.src_src_attenion.key_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.src_src_attenion.key_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.src_src_attenion.query_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.src_src_attenion.query_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.src_src_attenion.value_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.src_src_attenion.value_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.src_src_attenion.output_layer.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.src_src_attenion.output_layer.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.1.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.layer_norm.weight               [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.layer_norm.bias                 [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.src_src_attenion.key_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.src_src_attenion.key_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.src_src_attenion.query_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.src_src_attenion.query_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.src_src_attenion.value_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.src_src_attenion.value_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.src_src_attenion.output_layer.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.src_src_attenion.output_layer.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.2.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.layer_norm.weight               [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.layer_norm.bias                 [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.src_src_attenion.key_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.src_src_attenion.key_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.src_src_attenion.query_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.src_src_attenion.query_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.src_src_attenion.value_project.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.src_src_attenion.value_project.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.src_src_attenion.output_layer.weight [512, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.src_src_attenion.output_layer.bias [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.3.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.layer_norm.weight               [512]
2023-03-06 16:05:07,338 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.layer_norm.bias                 [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.src_src_attenion.key_project.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.src_src_attenion.key_project.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.src_src_attenion.query_project.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.src_src_attenion.query_project.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.src_src_attenion.value_project.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.src_src_attenion.value_project.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.src_src_attenion.output_layer.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.src_src_attenion.output_layer.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.4.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.layer_norm.weight               [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.layer_norm.bias                 [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.src_src_attenion.key_project.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.src_src_attenion.key_project.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.src_src_attenion.query_project.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.src_src_attenion.query_project.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.src_src_attenion.value_project.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.src_src_attenion.value_project.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.src_src_attenion.output_layer.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.src_src_attenion.output_layer.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layers.5.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layer_norm.weight                        [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_encoder.layer_norm.bias                          [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.0.gnn.lin_l.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.0.gnn.lin_l.bias                          [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.0.gnn.lin_r.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.0.layer_norm.weight                       [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.0.layer_norm.bias                         [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.1.gnn.lin_l.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.1.gnn.lin_l.bias                          [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.1.gnn.lin_r.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.1.layer_norm.weight                       [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.1.layer_norm.bias                         [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.2.gnn.lin_l.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.2.gnn.lin_l.bias                          [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.2.gnn.lin_r.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.2.layer_norm.weight                       [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.2.layer_norm.bias                         [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.3.gnn.lin_l.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.3.gnn.lin_l.bias                          [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.3.gnn.lin_r.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.3.layer_norm.weight                       [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.3.layer_norm.bias                         [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.4.gnn.lin_l.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.4.gnn.lin_l.bias                          [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.4.gnn.lin_r.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.4.layer_norm.weight                       [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.4.layer_norm.bias                         [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.5.gnn.lin_l.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.5.gnn.lin_l.bias                          [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.5.gnn.lin_r.weight                        [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.5.layer_norm.weight                       [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): gnn_encoder.layers.5.layer_norm.bias                         [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.trg_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.trg_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.trg_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.trg_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.trg_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,339 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.trg_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.trg_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.trg_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.src_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.src_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.src_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.src_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.src_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.src_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.src_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.src_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.layer_norm.weight               [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.layer_norm.bias                 [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.layer_norm2.weight              [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.0.layer_norm2.bias                [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.trg_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.trg_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.trg_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.trg_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.trg_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.trg_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.trg_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.trg_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.src_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.src_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.src_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.src_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.src_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.src_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.src_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.src_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.layer_norm.weight               [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.layer_norm.bias                 [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.layer_norm2.weight              [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.1.layer_norm2.bias                [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.trg_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.trg_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.trg_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.trg_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.trg_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.trg_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.trg_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.trg_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.src_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.src_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.src_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.src_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.src_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.src_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.src_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.src_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,340 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.layer_norm.weight               [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.layer_norm.bias                 [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.layer_norm2.weight              [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.2.layer_norm2.bias                [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.trg_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.trg_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.trg_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.trg_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.trg_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.trg_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.trg_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.trg_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.src_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.src_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.src_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.src_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.src_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.src_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.src_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.src_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.layer_norm.weight               [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.layer_norm.bias                 [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.layer_norm2.weight              [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.3.layer_norm2.bias                [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.trg_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.trg_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.trg_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.trg_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.trg_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.trg_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.trg_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.trg_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.src_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.src_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.src_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.src_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.src_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.src_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.src_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.src_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.layer_norm.weight               [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.layer_norm.bias                 [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.layer_norm2.weight              [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.4.layer_norm2.bias                [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.trg_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.trg_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.trg_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.trg_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.trg_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.trg_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.trg_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.trg_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.src_trg_attention.key_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.src_trg_attention.key_project.bias [512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.src_trg_attention.query_project.weight [512, 512]
2023-03-06 16:05:07,341 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.src_trg_attention.query_project.bias [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.src_trg_attention.value_project.weight [512, 512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.src_trg_attention.value_project.bias [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.src_trg_attention.output_layer.weight [512, 512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.src_trg_attention.output_layer.bias [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.feed_forward.layer_norm.weight  [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.feed_forward.layer_norm.bias    [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.feed_forward.pwff.0.weight      [2048, 512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.feed_forward.pwff.0.bias        [2048]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.feed_forward.pwff.3.weight      [512, 2048]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.feed_forward.pwff.3.bias        [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.layer_norm.weight               [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.layer_norm.bias                 [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.layer_norm2.weight              [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layers.5.layer_norm2.bias                [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layer_norm.weight                        [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): transformer_decoder.layer_norm.bias                          [512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): src_embed.lut.weight                                         [26684, 512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): learnable_embed.learn_lut.weight                             [400, 512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): position_embed.lut.weight                                    [20587, 512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): trg_embed.lut.weight                                         [13207, 512]
2023-03-06 16:05:07,342 - DEBUG - model - Trainable parameters(name): output_layer.weight                                          [13207, 512]
2023-03-06 16:05:07,343 - INFO - __main__ - ********************8 GPUs are used.********************
2023-03-06 16:05:09,393 - INFO - __main__ - Adam(lr=0.0001, weight_decay=0)
